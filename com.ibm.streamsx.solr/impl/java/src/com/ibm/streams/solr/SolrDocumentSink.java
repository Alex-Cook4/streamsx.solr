/* Generated by Streams Studio: December 11, 2015 12:07:35 PM EST */
package com.ibm.streams.solr;


import java.util.HashMap;
import java.util.Map;

import org.apache.log4j.Logger;

import com.ibm.streams.operator.AbstractOperator;
import com.ibm.streams.operator.OperatorContext;
import com.ibm.streams.operator.OutputTuple;
import com.ibm.streams.operator.StreamingInput;
import com.ibm.streams.operator.StreamingOutput;
import com.ibm.streams.operator.Tuple;
import com.ibm.streams.operator.TupleAttribute;
import com.ibm.streams.operator.Type.MetaType;
import com.ibm.streams.operator.log4j.TraceLevel;
import com.ibm.streams.operator.model.InputPortSet;
import com.ibm.streams.operator.model.InputPortSet.WindowMode;
import com.ibm.streams.operator.model.InputPortSet.WindowPunctuationInputMode;
import com.ibm.streams.operator.model.InputPorts;
import com.ibm.streams.operator.model.Libraries;
import com.ibm.streams.operator.model.OutputPortSet;
import com.ibm.streams.operator.model.OutputPorts;
import com.ibm.streams.operator.model.Parameter;
import com.ibm.streams.operator.model.PrimitiveOperator;
import org.apache.solr.client.solrj.SolrClient;
import org.apache.solr.client.solrj.impl.HttpSolrClient;
import org.apache.solr.common.SolrInputDocument; 
import org.apache.solr.client.solrj.response.UpdateResponse;

/**
 * Class for an operator that consumes tuples and does not produce an output stream. 
 * This pattern supports a number of input streams and no output streams. 
 * <P>
 * The following event methods from the Operator interface can be called:
 * </p>
 * <ul>
 * <li><code>initialize()</code> to perform operator initialization</li>
 * <li>allPortsReady() notification indicates the operator's ports are ready to process and submit tuples</li> 
 * <li>process() handles a tuple arriving on an input port 
 * <li>processPuncuation() handles a punctuation mark arriving on an input port 
 * <li>shutdown() to shutdown the operator. A shutdown request may occur at any time, 
 * such as a request to stop a PE or cancel a job. 
 * Thus the shutdown() may occur while the operator is processing tuples, punctuation marks, 
 * or even during port ready notification.</li>
 * </ul>
 * <p>With the exception of operator initialization, all the other events may occur concurrently with each other, 
 * which lead to these methods being called concurrently by different threads.</p> 
 */
@Libraries("opt/downloaded/*")
@PrimitiveOperator(name="SolrDocumentSink", namespace="com.ibm.streamsx.solr",
description="Java Operator SolrDocumentSink")
@InputPorts({@InputPortSet(description="Port that ingests tuples", cardinality=1, optional=false, windowingMode=WindowMode.NonWindowed, windowPunctuationInputMode=WindowPunctuationInputMode.Oblivious)})
@OutputPorts(@OutputPortSet(description="Error Port" , optional=true) ) 
public class SolrDocumentSink extends AbstractOperator {
	SolrClient solrClient; 
	TupleAttribute<Tuple, String> uniqueIdentifierAttribute;
	
	private final Logger trace = Logger.getLogger(SolrDocumentSink.class
			.getCanonicalName());
	private boolean validErrorPort = false;
	private String collection;
	private String solrURL;
    /**
     * Initialize this operator. Called once before any tuples are processed.
     * @param context OperatorContext for this operator.
     * @throws Exception Operator failure, will cause the enclosing PE to terminate.
     */
	@Override
	public synchronized void initialize(OperatorContext context)
			throws Exception {
    	// Must call super.initialize(context) to correctly setup an operator.
		super.initialize(context);
        Logger.getLogger(this.getClass()).trace("Operator " + context.getName() + " initializing in PE: " + context.getPE().getPEId() + " in Job: " + context.getPE().getJobId() );
        String collectionURL = solrURL + "/" + collection;
        solrClient = new HttpSolrClient(collectionURL);
        if (!context.getStreamingOutputs().isEmpty()){
        	StreamingOutput<OutputTuple> output = context.getStreamingOutputs().get(0);
        	if (output.getStreamSchema().getAttribute(0).getType().getMetaType() ==  MetaType.RSTRING){
        		validErrorPort = true;
        		trace.log(TraceLevel.INFO, "Found a valid error port to submit errors to.");
        	} 
        }
        
        if (!validErrorPort){
        	trace.log(TraceLevel.WARN, "No valid error port was found to submit errors to. Attribute must be of type rstring");
        }
	}

    /**
     * Process an incoming tuple that arrived on the specified port.
     * @param stream Port the tuple is arriving on.
     * @param tuple Object representing the incoming tuple.
     * @throws Exception Operator failure, will cause the enclosing PE to terminate.
     */
    @Override
    public void process(StreamingInput<Tuple> stream, Tuple tuple)
            throws Exception {    	
    	SolrInputDocument doc = new SolrInputDocument();
    	
    	try{
    		doc.addField(uniqueIdentifierAttribute.getAttribute().getName(), uniqueIdentifierAttribute.getValue(tuple));
    	} catch (Exception e) {
    		e.printStackTrace();
    		trace.log(TraceLevel.ERROR, "Failed to add unique identifier field: " + e.getMessage());
    		submitToErrorPort(e);
    	}
    	
    	@SuppressWarnings("unchecked")
		Map<String,String> atomicUpdateMap = (Map<String, String>) tuple.getMap("atomicUpdateMap");
    	
    	for (Map.Entry<String, String> entry : atomicUpdateMap.entrySet()){
    		Map<String,Object> fieldModifier = new HashMap<>(1);
    		String attributeName = entry.getKey();
    		String atomicAction = entry.getValue();
	        fieldModifier.put(atomicAction, tuple.getObject(attributeName));
	        try {
	        	doc.addField(attributeName, fieldModifier);
	        } catch (Exception e){
	        	e.printStackTrace();
	        	trace.log(TraceLevel.ERROR, "Failed to add field to document: " + e.getMessage());
	        	submitToErrorPort(e);
	        }
    	}
    	
    	//Add the document
    	try {
    		UpdateResponse response = solrClient.add(doc);
    		trace.log(TraceLevel.INFO, "Solr Client add response status: " + response.getStatus());
    		solrClient.commit();
    	} catch (Exception e){
    		e.printStackTrace();
    		trace.log(TraceLevel.ERROR, "Error while committing document: " + e.getMessage() );
    		submitToErrorPort(e);
    	}
    	
    }
    
    private void submitToErrorPort(Exception e) {
    	if(validErrorPort){
    	StreamingOutput<OutputTuple> streamingOutput = getOutput(0);
		OutputTuple otup = streamingOutput.newTuple();
    	otup.setString(0, e.getMessage());
    	try {
			streamingOutput.submit(otup);
		} catch (Exception e1) {
			e1.printStackTrace();
		}
    	}
	}

	@Parameter(optional = false)
    public void setUniqueIdentifierAttribute(TupleAttribute<Tuple, String> attributeName){
    	uniqueIdentifierAttribute = attributeName;
    }
    
    @Parameter(optional = false)
    public void setSolrURL(String value){
    	solrURL = value;
    }
    
    @Parameter(optional = false)
    public void setCollection(String value){
    	collection = value;
    }

    /**
     * Shutdown this operator.
     * @throws Exception Operator failure, will cause the enclosing PE to terminate.
     */
    @Override
    public synchronized void shutdown() throws Exception {
        OperatorContext context = getOperatorContext();
        Logger.getLogger(this.getClass()).trace("Operator " + context.getName() + " shutting down in PE: " + context.getPE().getPEId() + " in Job: " + context.getPE().getJobId() );
        solrClient.close();
        super.shutdown();
    }
    
}
